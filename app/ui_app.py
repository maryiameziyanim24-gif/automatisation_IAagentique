import os
import sys

# Ensure repository root is on sys.path so 'app' package resolves
APP_DIR = os.path.abspath(os.path.dirname(__file__))
ROOT = os.path.abspath(os.path.join(APP_DIR, '..'))
for p in (ROOT,):
    if p not in sys.path:
        sys.path.insert(0, p)

import io
import time
import base64
import streamlit as st
from typing import List

from app.orchestrator import analyze_pdfs
from app.llm_client import is_configured as llm_ready
from app.llm_client import has_model, list_models

UPLOAD_DIR = os.path.join("data", "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)

st.set_page_config(page_title="Analyseur multi-agents de PDF", layout="wide")
st.title("Analyseur multi-agents de PDF")
st.caption("Types: article, contrat, cv, cours, autre. Heuristiques avec option LLM (Mistral AI).")

with st.sidebar:
    st.header("Options")
    st.info("üí° Conseil: D√©sactivez le LLM pour une analyse rapide (5-10s), activez-le pour plus de pr√©cision avec Mistral (~30s-1min).")
    use_llm = st.checkbox("Activer LLM (Mistral AI)", value=False)
    
    # Get available models
    available_models = list_models() if llm_ready() else []
    if available_models:
        llm_model = st.selectbox(
            "Mod√®le Mistral",
            options=available_models,
            index=0,
            help="S√©lectionnez un mod√®le. mistral-small = rapide, mistral-large = pr√©cis"
        )
    else:
        llm_model = st.text_input("Mod√®le Mistral", value="mistral-small-latest", help="Ex: mistral-small-latest")
    
    if use_llm and not llm_ready():
        st.warning("MISTRAL_API_KEY manquante. D√©finissez-la dans l'environnement.")
    detection_mode = st.radio(
        "Mode de d√©tection",
        options=["Auto", "Al√©atoire"],
        index=0,
        help="'Al√©atoire' choisit un type au hasard (article/contrat/cv/cours/autre)."
    )

uploaded_files = st.file_uploader(
    "Choisissez un ou plusieurs fichiers PDF",
    type=["pdf"],
    accept_multiple_files=True,
    help="Glissez-d√©posez vos PDF ici."
)

col1, col2 = st.columns([1,1])
with col1:
    run_btn = st.button("Analyser")
with col2:
    st.write("")


def _save_uploaded(files) -> List[str]:
    paths = []
    for f in files:
        name = f.name
        base, ext = os.path.splitext(name)
        ts = int(time.time() * 1000)
        safe = f"{base}_{ts}{ext}"
        path = os.path.join(UPLOAD_DIR, safe)
        with open(path, "wb") as out:
            out.write(f.read())
        paths.append(path)
    return paths

if run_btn and uploaded_files:
    with st.spinner("Analyse en cours..."):
        file_paths = _save_uploaded(uploaded_files)
        start = time.time()
        results = analyze_pdfs(
            file_paths,
            use_llm=use_llm and llm_ready(),
            llm_model=llm_model if use_llm else None,
            force_type=None,
            detection_mode=("random" if detection_mode == "Al√©atoire" else None),
        )
        elapsed = time.time() - start

    st.success(f"Analyse termin√©e en {elapsed:.2f}s")

    for doc in results:
        st.markdown(f"### R√©sultat: {doc['filename']}")
        st.write(f"Type d√©tect√©: **{doc['document_type']}** (confiance {doc.get('type_confidence', 0):.2f})")
        st.write(f"Pages: {doc.get('num_pages')}")

        # R√©sum√©
        with st.expander("R√©sum√© et points cl√©s", expanded=True):
            st.markdown("#### R√©sum√© ex√©cutif")
            st.write(doc["synthesis"]["summary"]) 
            st.markdown("#### Points cl√©s")
            for p in doc["synthesis"]["key_points"]:
                st.write("- " + p)
            if doc["synthesis"].get("risks_or_remarks"):
                st.markdown("#### Risques / remarques")
                for r in doc["synthesis"]["risks_or_remarks"]:
                    st.write("- " + r)

        # Alertes
        with st.expander("Alertes / V√©rification", expanded=False):
            alerts = doc["verification"]["alerts"]
            if alerts:
                for a in alerts:
                    st.error(a)
            else:
                st.info("Aucune alerte majeure d√©tect√©e (heuristique).")

        # Visualisations
        visualizations = doc.get("visualizations", {})
        if visualizations and visualizations.get("status") == "generated":
            with st.expander("üìä Visualisations (Graphiques, Nuages de Mots, Mindmap)", expanded=False):
                st.markdown("### Visualisations G√©n√©r√©es")
                
                # Nuage de mots
                if visualizations.get("wordcloud"):
                    st.markdown("#### ‚òÅÔ∏è Nuage de Mots")
                    st.image(f"data:image/png;base64,{visualizations['wordcloud']}", use_container_width=True)
                    st.caption("Visualisation des mots les plus fr√©quents dans le document")
                    st.divider()
                
                # Graphiques statistiques
                if visualizations.get("statistics"):
                    st.markdown("#### üìà Statistiques")
                    st.image(f"data:image/png;base64,{visualizations['statistics']}", use_container_width=True)
                    st.caption("Analyse statistique du contenu extrait")
                    st.divider()
                
                # Mindmap
                if visualizations.get("mindmap"):
                    st.markdown("#### üß† Carte Mentale (Mindmap)")
                    st.image(f"data:image/png;base64,{visualizations['mindmap']}", use_container_width=True)
                    st.caption("Structure logique du document")
        elif visualizations and visualizations.get("status") == "unavailable":
            with st.expander("üìä Visualisations", expanded=False):
                st.warning("‚ö†Ô∏è Visualisations indisponibles. Installez les d√©pendances: `pip install wordcloud matplotlib networkx`")


        # D√©tails des agents
        with st.expander("üîç D√©tails des Agents (Pipeline)", expanded=False):
            st.markdown("### Pipeline d'analyse multi-agents")
            st.caption("Visualisez le travail de chaque agent dans le processus d'analyse")
            
            agent_details = doc.get("agent_details", {})
            
            # Agent 1: Ingestion
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('ingestion', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 1Ô∏è‚É£ Agent d'Ingestion")
                    st.write(f"**R√¥le**: Extraire le texte brut du PDF page par page")
                    st.write(f"**R√©sultat**: {agent_details.get('ingestion', {}).get('description', 'N/A')}")
                st.divider()
            
            # Agent 2: D√©tection
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('detection', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 2Ô∏è‚É£ Agent de D√©tection")
                    st.write(f"**R√¥le**: Identifier le type de document (article, contrat, CV, cours, autre)")
                    st.write(f"**R√©sultat**: {agent_details.get('detection', {}).get('description', 'N/A')}")
                    det_data = agent_details.get('detection', {}).get('data', {})
                    if det_data:
                        st.json(det_data)
                st.divider()
            
            # Agent 3: Structuration
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('structuration', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 3Ô∏è‚É£ Agent de Structuration")
                    st.write(f"**R√¥le**: Segmenter le document en sections logiques")
                    st.write(f"**R√©sultat**: {agent_details.get('structuration', {}).get('description', 'N/A')}")
                    struct_data = agent_details.get('structuration', {}).get('data', {})
                    if struct_data.get('sections'):
                        st.write("**Sections identifi√©es**:")
                        for i, section in enumerate(struct_data['sections'][:10], 1):
                            st.write(f"{i}. {section}")
                        if len(struct_data['sections']) > 10:
                            st.caption(f"... et {len(struct_data['sections']) - 10} autres sections")
                st.divider()
            
            # Agent 4: Extraction
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('extraction', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 4Ô∏è‚É£ Agent d'Extraction")
                    st.write(f"**R√¥le**: Extraire les informations structur√©es selon le type de document")
                    st.write(f"**R√©sultat**: {agent_details.get('extraction', {}).get('description', 'N/A')}")
                    ext_data = agent_details.get('extraction', {}).get('data', {})
                    if ext_data.get('fields'):
                        st.write("**Champs extraits**:", ", ".join(ext_data['fields']))
                        st.caption(f"M√©thode: {ext_data.get('method', 'N/A')}")
                st.divider()
            
            # Agent 5: Synth√®se
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('synthese', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 5Ô∏è‚É£ Agent de Synth√®se")
                    st.write(f"**R√¥le**: G√©n√©rer un r√©sum√© ex√©cutif et identifier les points cl√©s")
                    st.write(f"**R√©sultat**: {agent_details.get('synthese', {}).get('description', 'N/A')}")
                    synth_data = agent_details.get('synthese', {}).get('data', {})
                    if synth_data:
                        st.caption(f"Longueur r√©sum√©: {synth_data.get('summary_length', 0)} caract√®res")
                        st.caption(f"M√©thode: {synth_data.get('method', 'N/A')}")
                st.divider()
            
            # Agent 6: V√©rification
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('verification', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 6Ô∏è‚É£ Agent de V√©rification")
                    st.write(f"**R√¥le**: V√©rifier la coh√©rence et identifier les anomalies potentielles")
                    st.write(f"**R√©sultat**: {agent_details.get('verification', {}).get('description', 'N/A')}")
                    ver_data = agent_details.get('verification', {}).get('data', {})
                    if ver_data:
                        severity = ver_data.get('severity', 'N/A')
                        if severity == "Haute":
                            st.error(f"‚ö†Ô∏è S√©v√©rit√©: {severity}")
                        else:
                            st.success(f"‚úÖ S√©v√©rit√©: {severity}")
                st.divider()
            
            # Agent 7: Visualisation
            with st.container():
                col1, col2 = st.columns([1, 5])
                with col1:
                    st.markdown(f"### {agent_details.get('visualisation', {}).get('status', '‚è≥')}")
                with col2:
                    st.markdown("#### 7Ô∏è‚É£ Agent de Visualisation")
                    st.write(f"**R√¥le**: G√©n√©rer des graphiques, nuages de mots et mindmaps")
                    st.write(f"**R√©sultat**: {agent_details.get('visualisation', {}).get('description', 'N/A')}")
                    viz_data = agent_details.get('visualisation', {}).get('data', {})
                    if viz_data:
                        st.write(f"- Nuage de mots: {viz_data.get('wordcloud', 'N/A')}")
                        st.write(f"- Statistiques: {viz_data.get('statistics', 'N/A')}")
                        st.write(f"- Mindmap: {viz_data.get('mindmap', 'N/A')}")

        # Rapport PDF
        rp = doc["report_path"]
        if os.path.exists(rp):
            st.markdown("### üìÑ Rapport PDF")
            
            with open(rp, "rb") as f:
                pdf_bytes = f.read()
            
            # Bouton pour t√©l√©charger
            st.download_button(
                label="üì• T√©l√©charger le rapport PDF",
                data=pdf_bytes,
                file_name=os.path.basename(rp),
                mime="application/pdf",
                use_container_width=True
            )
            
            st.info("üí° T√©l√©chargez le rapport et ouvrez-le avec votre lecteur PDF pour le consulter.")
        
        st.divider()

st.markdown("---")
